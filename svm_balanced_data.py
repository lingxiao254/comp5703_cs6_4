# -*- coding: utf-8 -*-
"""SVM_balanced_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UjZkQJaI05qN9zNciN8JBLfJdxW6fnFK
"""

# Use GPU
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

!apt-get install -y -qq software-properties-common python-software-properties module-init-tools
!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
!apt-get update -qq 2>&1 > /dev/null
!apt-get -y install -qq google-drive-ocamlfuse fuse
from google.colab import auth
auth.authenticate_user()
from oauth2client.client import GoogleCredentials
creds = GoogleCredentials.get_application_default()
import getpass
!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
vcode = getpass.getpass()
!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}

# Make google drive directory
!mkdir -p drive
!google-drive-ocamlfuse -o nonempty drive

# Mount drive
from google.colab import drive
drive.mount('/content/drive')

import os
os.getcwd()
os.chdir('/content/drive/My Drive')
os.getcwd()

#import library
import pandas as pd
import numpy as np
from glob import glob
import fnmatch
import cv2
from glob import glob
import pandas as pd
import numpy as np
import fnmatch
import cv2
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
import matplotlib.pyplot as plt
import numpy as np
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

x_sub=np.load('X.npy')
y_sub=np.load('Y.npy')

x_sub = np.array(x_sub)
x_sub_shape = x_sub.shape[1] * x_sub.shape[2] * x_sub.shape[3]
x_flat = x_sub.reshape(x_sub.shape[0], x_sub_shape)
r = pd.value_counts(y_sub)
print(r)
from imblearn.under_sampling import RandomUnderSampler
rus=RandomUnderSampler(ratio='auto')
x_flat_resample,y_sub_resample=rus.fit_sample(x_flat,y_sub)
len(x_flat_resample)
r = pd.value_counts(y_sub_resample)
print(r)
print('length of X_flat_resample',len(x_flat_resample))
print('length of Y_flat_resample',len(y_sub_resample))

plt.imshow(x_sub[0]) # followed by 
plt.show()

#standardise data and do PCA 
standardised_X = StandardScaler().fit_transform(x_flat_resample)
pca = PCA(n_components=6,whiten=True) 
pca.fit(standardised_X) 
transformed_X=pca.transform(standardised_X) 
print(len(transformed_X))
print(transformed_X[0])

X_train, X_test, y_train, y_test = train_test_split(transformed_X, y_sub_resample, test_size=0.2, random_state = 2) # 0.2 test_size means 20%
print(len(X_train), len(y_train), len(X_test),len(y_test))

# Commented out IPython magic to ensure Python compatibility.
#SVM
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
# use seaborn plotting defaults
import seaborn as sns; sns.set()

from sklearn.svm import SVC # "Support vector classifier"
clf = SVC(kernel='rbf')
clf.fit(X_train,y_train)
y_pred=clf.predict(X_test)

from sklearn import metrics
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import roc_auc_score
import itertools
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report


def plot_cm(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):
    plt.figure(figsize = (5,5))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=90)
    plt.yticks(tick_marks, classes)
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    
def plot_lc(history):
    plt.figure(figsize=(8,8))
    plt.subplot(1,2,1)
    plt.plot(history.history['acc'])
    plt.plot(history.history['val_acc'])
    plt.title('model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.savefig('./accuracy_curve.png')
    plt.subplot(1,2,2)
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')

dict_characters = {0: 'IDC(-)', 1: 'IDC(+)'}
confusion_mtx = confusion_matrix(y_test, y_pred) 
plot_cm(confusion_mtx, classes = list(dict_characters.values())) 
plt.show()

accuracy_score(y_test, y_pred, normalize=True)

print(metrics.classification_report(y_test,y_pred))

roc_auc_score(y_test, y_pred)

